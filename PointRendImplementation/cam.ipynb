{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae044630-0d83-4091-aa9f-b76fe2bcd6de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pixellib\n",
    "from pixellib.torchbackend.instance import instanceSegmentation\n",
    "import cv2\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5be73b-cab8-4efc-a722-ca8b0e7c8f03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "Using cache found in /home/adit/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/adit/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "segment_video = instanceSegmentation()\n",
    "segment_video.load_model(\"pointrend_resnet50.pkl\",detection_speed=\"fast\")\n",
    "target_classes = segment_video.select_target_classes(person = True,bicycle = True, car = True, motorcycle= True,bus= True,truck= True, \n",
    "                                           fire_hydrant= True, stop_sign= True, parking_meter= True, bench= True\n",
    "                                          )\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c45c82e-36bc-4602-840b-7a8302415ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_instance_boundary(instance_mask,height,width):\n",
    "    instance_boundary = np.zeros((int(height),int(width)))\n",
    "    for i in instance_mask:\n",
    "        instance_boundary[i[1]][i[0]] = 1\n",
    "    return instance_boundary\n",
    "\n",
    "def check_mask(mask):\n",
    "    mask_segments = len(mask)\n",
    "    if mask_segments > 1:\n",
    "        max_idx = 0\n",
    "        max_len = 0\n",
    "        for i in range(mask_segments):\n",
    "            tmp = len(mask[i])\n",
    "            if tmp > max_len:\n",
    "                max_len = tmp\n",
    "                max_idx = i\n",
    "        ret_mask = mask[max_idx]\n",
    "    else:\n",
    "        ret_mask = mask[0]\n",
    "    return ret_mask\n",
    "\n",
    "def get_mean_distance(depth_map,instance_boundary):\n",
    "    distance_map = (1/depth_map)*1000\n",
    "    object_boundary = np.multiply(distance_map,instance_boundary)\n",
    "    count = 0\n",
    "    for i in object_boundary:\n",
    "        for j in i:\n",
    "            if j>0:\n",
    "                count += 1\n",
    "    mean_distance = np.sum(object_boundary)/count\n",
    "    return mean_distance\n",
    "\n",
    "def create_positional_list(class_names,masks,output):\n",
    "    positional_list = list()\n",
    "    for idx, name in enumerate(class_names):\n",
    "        mask = check_mask(masks[idx])\n",
    "        instance_boundary = get_instance_boundary(mask,height,width)\n",
    "        mean_distance = get_mean_distance(output,instance_boundary)\n",
    "        tmp_dict = {'class_name':name,'mean_distance': mean_distance}    \n",
    "        positional_list.append(tmp_dict)\n",
    "    return positional_list\n",
    "\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 112) \n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b787df07-22ca-4289-9412-a9709420f5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8618791904300451\n",
      "Please be alert there is a car coming towards you\n",
      "0.8679078946942869\n",
      "Please be alert there is a car coming towards you\n",
      "0.8633994447941683\n",
      "Please be alert there is a truck coming towards you\n",
      "0.7329586165052064\n",
      "Please be alert there is a car coming towards you\n",
      "0.7664462712903818\n",
      "Please be alert there is a car coming towards you\n",
      "0.5735914102524002\n",
      "Please be alert there is a person coming towards you\n"
     ]
    }
   ],
   "source": [
    "depth_map = masks =  class_names  = list()\n",
    "resu = []\n",
    "cap = cv2.VideoCapture(-1)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH )\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT )\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Instance segmentation\n",
    "    res = segment_video.segmentFrame(frame,\n",
    "                                     segment_target_classes= target_classes,\n",
    "                                     mask_points_values=True)\n",
    "    masks = res[0]['masks']\n",
    "    class_names = res[0]['class_names']\n",
    "    image = res[1]\n",
    "    cv2.imshow('Instance Segmentation', image)\n",
    "\n",
    "    #Depth Mapping\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_batch = transform(img).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "        \n",
    "        depth_map = prediction.cpu().numpy()\n",
    "        positional_list = create_positional_list(class_names,masks,depth_map)\n",
    "        for i in positional_list:\n",
    "            if i['mean_distance'] < 5:\n",
    "                print(i['mean_distance'])\n",
    "                text = f\"Please be alert there is a {i['class_name']} coming towards you\"\n",
    "                print(text)\n",
    "                speak(text)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce50ca4-cebe-474c-a084-e13abb76321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec29dc48-16fe-4626-a44a-a8d8408556fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9cbc320-d088-4e01-b3f8-0fd4a1cab914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3116437  1.3131962  1.3172106  ... 2.141976   2.4051151  2.5498366 ]\n",
      " [1.3153832  1.3160732  1.3181812  ... 2.1085997  2.3279576  2.4456408 ]\n",
      " [1.3282143  1.3262472  1.3225685  ... 2.029001   2.15222    2.2148237 ]\n",
      " ...\n",
      " [0.35039243 0.35044178 0.35047305 ... 0.6281327  0.62910354 0.62952954]\n",
      " [0.35022214 0.35025615 0.35022512 ... 0.62683433 0.6274361  0.62770694]\n",
      " [0.3501146  0.35014945 0.35011068 ... 0.6262101  0.6267089  0.6269356 ]]\n"
     ]
    }
   ],
   "source": [
    "print((1/depth_map)*1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
